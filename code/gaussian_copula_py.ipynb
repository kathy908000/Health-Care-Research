{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Expectation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "#import scipy.cluster.hierarchy as sch\n",
    "\n",
    "#import April12.ipynb\n",
    "#%store -r icd_grouped \n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices \n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "import seaborn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms.transform_function import TransformFunction\n",
    "from scipy.stats import norm, truncnorm\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# call class, contruct object of the class, \n",
    "#from application.app.folder.file import impute_missing\n",
    "\n",
    "from batch_expectation_maximization import BatchExpectationMaximization\n",
    "\n",
    "#Users.kathy908000.github.online_mixed_gc_imp.em.batch_expectation_maximization.py import BatchExpectationMaximization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>LOS</th>\n",
       "      <th>HOSPITALIZATION</th>\n",
       "      <th>ORDINAL_AGE</th>\n",
       "      <th>ELECTIVE</th>\n",
       "      <th>EMERGENCY</th>\n",
       "      <th>NEWBORN</th>\n",
       "      <th>URGENT</th>\n",
       "      <th>Government</th>\n",
       "      <th>Medicaid</th>\n",
       "      <th>...</th>\n",
       "      <th>NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER</th>\n",
       "      <th>HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)</th>\n",
       "      <th>ASIAN - JAPANESE</th>\n",
       "      <th>ASIAN - THAI</th>\n",
       "      <th>HISPANIC/LATINO - HONDURAN</th>\n",
       "      <th>HISPANIC/LATINO - CUBAN</th>\n",
       "      <th>MIDDLE EASTERN</th>\n",
       "      <th>ASIAN - OTHER</th>\n",
       "      <th>HISPANIC/LATINO - MEXICAN</th>\n",
       "      <th>AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>3.6660</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1.2885</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0508</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>14.2664</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>3.5466</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>1.1224</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35</td>\n",
       "      <td>5.3757</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37</td>\n",
       "      <td>1.1397</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55</td>\n",
       "      <td>1.9138</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>59</td>\n",
       "      <td>2.2017</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75</td>\n",
       "      <td>1.2469</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>83</td>\n",
       "      <td>2.3141</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>117</td>\n",
       "      <td>14.5181</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>123</td>\n",
       "      <td>1.4941</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>130</td>\n",
       "      <td>17.4592</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>135</td>\n",
       "      <td>1.3460</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>137</td>\n",
       "      <td>5.1326</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>141</td>\n",
       "      <td>3.4765</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>157</td>\n",
       "      <td>6.1813</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>173</td>\n",
       "      <td>1.3722</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>184</td>\n",
       "      <td>5.0941</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>186</td>\n",
       "      <td>3.7078</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>188</td>\n",
       "      <td>26.9190</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>191</td>\n",
       "      <td>10.1558</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>192</td>\n",
       "      <td>1.0840</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>199</td>\n",
       "      <td>7.1739</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>205</td>\n",
       "      <td>2.9076</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>209</td>\n",
       "      <td>8.3211</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>210</td>\n",
       "      <td>1.0253</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 921 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SUBJECT_ID      LOS  HOSPITALIZATION  ORDINAL_AGE  ELECTIVE  EMERGENCY  \\\n",
       "0           13   3.6660                1            4         0          1   \n",
       "1           18   1.2885                1            6         0          1   \n",
       "2           20   1.0508                1            8         1          0   \n",
       "3           21  14.2664                2            9         0          1   \n",
       "4           24   0.5124                1            4         0          1   \n",
       "5           25   3.5466                1            6         0          1   \n",
       "6           28   1.1224                1            8         1          0   \n",
       "7           35   5.3757                1            7         1          0   \n",
       "8           37   1.1397                1            7         0          1   \n",
       "9           55   1.9138                1            7         0          1   \n",
       "10          59   2.2017                1            9         0          1   \n",
       "11          75   1.2469                1            8         1          0   \n",
       "12          83   2.3141                1            7         0          0   \n",
       "13         117  14.5181                2            5         0          1   \n",
       "14         123   1.4941                1            6         0          1   \n",
       "15         130  17.4592                2            7         0          1   \n",
       "16         135   1.3460                2            6         1          1   \n",
       "17         137   5.1326                1            8         0          1   \n",
       "18         141   3.4765                1            9         0          1   \n",
       "19         157   6.1813                2            9         0          1   \n",
       "20         173   1.3722                1            7         1          0   \n",
       "21         184   5.0941                2            6         0          1   \n",
       "22         186   3.7078                1            8         0          1   \n",
       "23         188  26.9190                7            6         0          1   \n",
       "24         191  10.1558                2            8         0          1   \n",
       "25         192   1.0840                1            7         1          0   \n",
       "26         199   7.1739                2            5         0          1   \n",
       "27         205   2.9076                1            8         0          0   \n",
       "28         209   8.3211                2            8         0          1   \n",
       "29         210   1.0253                1            6         0          1   \n",
       "\n",
       "    NEWBORN  URGENT  Government  Medicaid  ...  \\\n",
       "0         0       0           0         1  ...   \n",
       "1         0       0           0         0  ...   \n",
       "2         0       0           0         0  ...   \n",
       "3         0       0           0         0  ...   \n",
       "4         0       0           0         0  ...   \n",
       "5         0       0           0         0  ...   \n",
       "6         0       0           0         0  ...   \n",
       "7         0       0           0         0  ...   \n",
       "8         0       0           0         0  ...   \n",
       "9         0       0           0         0  ...   \n",
       "10        0       0           0         0  ...   \n",
       "11        0       0           0         0  ...   \n",
       "12        0       1           0         0  ...   \n",
       "13        0       0           0         1  ...   \n",
       "14        0       0           1         0  ...   \n",
       "15        0       0           0         0  ...   \n",
       "16        0       0           0         0  ...   \n",
       "17        0       0           0         0  ...   \n",
       "18        0       0           0         0  ...   \n",
       "19        0       0           0         0  ...   \n",
       "20        0       0           0         0  ...   \n",
       "21        0       0           0         0  ...   \n",
       "22        0       0           0         0  ...   \n",
       "23        0       0           0         0  ...   \n",
       "24        0       0           0         0  ...   \n",
       "25        0       0           0         0  ...   \n",
       "26        0       1           1         0  ...   \n",
       "27        0       1           0         0  ...   \n",
       "28        0       0           0         0  ...   \n",
       "29        0       0           0         0  ...   \n",
       "\n",
       "    NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "5                                           0   \n",
       "6                                           0   \n",
       "7                                           0   \n",
       "8                                           0   \n",
       "9                                           0   \n",
       "10                                          0   \n",
       "11                                          0   \n",
       "12                                          0   \n",
       "13                                          0   \n",
       "14                                          0   \n",
       "15                                          0   \n",
       "16                                          0   \n",
       "17                                          0   \n",
       "18                                          0   \n",
       "19                                          0   \n",
       "20                                          0   \n",
       "21                                          0   \n",
       "22                                          0   \n",
       "23                                          0   \n",
       "24                                          0   \n",
       "25                                          0   \n",
       "26                                          0   \n",
       "27                                          0   \n",
       "28                                          0   \n",
       "29                                          0   \n",
       "\n",
       "    HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)  ASIAN - JAPANESE  \\\n",
       "0                                            0                 0   \n",
       "1                                            0                 0   \n",
       "2                                            0                 0   \n",
       "3                                            0                 0   \n",
       "4                                            0                 0   \n",
       "5                                            0                 0   \n",
       "6                                            0                 0   \n",
       "7                                            0                 0   \n",
       "8                                            0                 0   \n",
       "9                                            0                 0   \n",
       "10                                           0                 0   \n",
       "11                                           0                 0   \n",
       "12                                           0                 0   \n",
       "13                                           0                 0   \n",
       "14                                           0                 0   \n",
       "15                                           0                 0   \n",
       "16                                           0                 0   \n",
       "17                                           0                 0   \n",
       "18                                           0                 0   \n",
       "19                                           0                 0   \n",
       "20                                           0                 0   \n",
       "21                                           0                 0   \n",
       "22                                           0                 0   \n",
       "23                                           0                 0   \n",
       "24                                           0                 0   \n",
       "25                                           0                 0   \n",
       "26                                           0                 0   \n",
       "27                                           0                 0   \n",
       "28                                           0                 0   \n",
       "29                                           0                 0   \n",
       "\n",
       "    ASIAN - THAI  HISPANIC/LATINO - HONDURAN  HISPANIC/LATINO - CUBAN  \\\n",
       "0              0                           0                        0   \n",
       "1              0                           0                        0   \n",
       "2              0                           0                        0   \n",
       "3              0                           0                        0   \n",
       "4              0                           0                        0   \n",
       "5              0                           0                        0   \n",
       "6              0                           0                        0   \n",
       "7              0                           0                        0   \n",
       "8              0                           0                        0   \n",
       "9              0                           0                        0   \n",
       "10             0                           0                        0   \n",
       "11             0                           0                        0   \n",
       "12             0                           0                        0   \n",
       "13             0                           0                        0   \n",
       "14             0                           0                        0   \n",
       "15             0                           0                        0   \n",
       "16             0                           0                        0   \n",
       "17             0                           0                        0   \n",
       "18             0                           0                        0   \n",
       "19             0                           0                        0   \n",
       "20             0                           0                        0   \n",
       "21             0                           0                        0   \n",
       "22             0                           0                        0   \n",
       "23             0                           0                        0   \n",
       "24             0                           0                        0   \n",
       "25             0                           0                        0   \n",
       "26             0                           0                        0   \n",
       "27             0                           0                        0   \n",
       "28             0                           0                        0   \n",
       "29             0                           0                        0   \n",
       "\n",
       "    MIDDLE EASTERN  ASIAN - OTHER  HISPANIC/LATINO - MEXICAN  \\\n",
       "0                0              0                          0   \n",
       "1                0              0                          0   \n",
       "2                0              0                          0   \n",
       "3                0              0                          0   \n",
       "4                0              0                          0   \n",
       "5                0              0                          0   \n",
       "6                0              0                          0   \n",
       "7                0              0                          0   \n",
       "8                0              0                          0   \n",
       "9                0              0                          0   \n",
       "10               0              0                          0   \n",
       "11               0              0                          0   \n",
       "12               0              0                          0   \n",
       "13               0              0                          0   \n",
       "14               0              0                          0   \n",
       "15               0              0                          0   \n",
       "16               0              0                          0   \n",
       "17               0              0                          0   \n",
       "18               0              0                          0   \n",
       "19               0              0                          0   \n",
       "20               0              0                          0   \n",
       "21               0              0                          0   \n",
       "22               0              0                          0   \n",
       "23               0              0                          0   \n",
       "24               0              0                          0   \n",
       "25               0              0                          0   \n",
       "26               0              0                          0   \n",
       "27               0              0                          0   \n",
       "28               0              0                          0   \n",
       "29               0              0                          0   \n",
       "\n",
       "    AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE  \n",
       "0                                                   0         \n",
       "1                                                   0         \n",
       "2                                                   0         \n",
       "3                                                   0         \n",
       "4                                                   0         \n",
       "5                                                   0         \n",
       "6                                                   0         \n",
       "7                                                   0         \n",
       "8                                                   0         \n",
       "9                                                   0         \n",
       "10                                                  0         \n",
       "11                                                  0         \n",
       "12                                                  0         \n",
       "13                                                  0         \n",
       "14                                                  0         \n",
       "15                                                  0         \n",
       "16                                                  0         \n",
       "17                                                  0         \n",
       "18                                                  0         \n",
       "19                                                  0         \n",
       "20                                                  0         \n",
       "21                                                  0         \n",
       "22                                                  0         \n",
       "23                                                  0         \n",
       "24                                                  0         \n",
       "25                                                  0         \n",
       "26                                                  0         \n",
       "27                                                  0         \n",
       "28                                                  0         \n",
       "29                                                  0         \n",
       "\n",
       "[30 rows x 921 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"/Users/kathy908000/github/health-care-research/data/Diabetes_Numerical.csv\")\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUBJECT_ID', 'LOS', 'HOSPITALIZATION', 'ORDINAL_AGE', 'ELECTIVE', 'EMERGENCY', 'NEWBORN', 'URGENT', 'Government', 'Medicaid', 'Medicare', 'Private', 'Self Pay', 'DIVORCED', 'LIFE PARTNER', 'MARRIED', 'NAN', 'SEPARATED', 'SINGLE', 'UNKNOWN', 'WIDOWED', 'GENDER', '3', '4', '5', '7', '8', '9', '10', '11', '12', '13', '14', '18', '27', '31', '32', '34', '35', '38', '39', '40', '41', '42', '46', '47', '48', '49', '52', '53', '54', '57', '58', '66', '70', '75', '78', '79', '82', '86', '88', '94', '96', '97', '110', '111', '112', '117', '120', '121', '127', '130', '131', '135', '136', '137', '138', '139', '140', '141', '142', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '161', '162', '163', '164', '171', '172', '173', '174', '175', '176', '180', '182', '183', '184', '185', '186', '187', '188', '189', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '220', '221', '223', '225', '226', '227', '228', '229', '230', '232', '233', '235', '236', '237', '238', '239', '240', '241', '242', '244', '245', '246', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '261', '262', '263', '265', '266', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '317', '318', '319', '320', '321', '322', '323', '324', '325', '327', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '382', '383', '385', '386', '387', '388', '389', '390', '391', '394', '395', '396', '397', '398', '401', '402', '403', '404', '405', '410', '411', '412', '413', '414', '415', '416', '417', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '451', '452', '453', '454', '455', '456', '457', '458', '459', '461', '462', '463', '464', '465', '466', '471', '472', '473', '475', '477', '478', '480', '481', '482', '483', '484', '485', '486', '487', '488', '490', '491', '492', '493', '494', '495', '496', '500', '501', '502', '506', '507', '508', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '540', '541', '542', '543', '550', '551', '552', '553', '555', '556', '557', '558', '560', '562', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '607', '608', '611', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '632', '633', '634', '642', '644', '646', '647', '648', '649', '652', '654', '666', '670', '674', '680', '681', '682', '683', '684', '685', '686', '690', '692', '693', '694', '695', '696', '697', '698', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '718', '719', '720', '721', '722', '723', '724', '725', '726', '727', '728', '729', '730', '731', '732', '733', '734', '735', '736', '737', '738', '741', '742', '745', '746', '747', '748', '750', '751', '752', '753', '754', '755', '756', '757', '758', '759', '765', '766', '770', '774', '775', '780', '781', '782', '783', '784', '785', '786', '787', '788', '789', '790', '791', '792', '793', '794', '795', '796', '799', '800', '801', '802', '803', '804', '805', '806', '807', '808', '810', '811', '812', '813', '814', '815', '816', '817', '820', '821', '822', '823', '824', '825', '826', '830', '831', '833', '834', '835', '836', '839', '840', '842', '845', '846', '847', '850', '851', '852', '853', '854', '860', '861', '862', '863', '864', '865', '866', '867', '868', '869', '870', '872', '873', '874', '875', '879', '880', '881', '882', '883', '884', '886', '887', '890', '891', '892', '893', '894', '896', '897', '900', '901', '902', '903', '904', '905', '906', '907', '908', '909', '910', '911', '912', '913', '914', '916', '917', '918', '919', '920', '921', '922', '923', '924', '926', '927', '933', '934', '935', '936', '937', '939', '941', '942', '944', '945', '947', '948', '950', '951', '952', '953', '954', '955', '956', '958', '959', '961', '962', '964', '965', '966', '967', '968', '969', '970', '971', '972', '974', '975', '977', '983', '987', '989', '990', '991', '992', '994', '995', '996', '997', '998', '999', 'E812', 'E813', 'E814', 'E815', 'E816', 'E817', 'E818', 'E819', 'E821', 'E822', 'E823', 'E824', 'E825', 'E826', 'E838', 'E848', 'E849', 'E850', 'E851', 'E852', 'E853', 'E854', 'E855', 'E857', 'E858', 'E866', 'E869', 'E870', 'E871', 'E874', 'E876', 'E878', 'E879', 'E880', 'E881', 'E882', 'E884', 'E885', 'E887', 'E888', 'E890', 'E899', 'E900', 'E901', 'E906', 'E910', 'E911', 'E912', 'E915', 'E916', 'E917', 'E918', 'E920', 'E922', 'E924', 'E927', 'E928', 'E929', 'E930', 'E931', 'E932', 'E933', 'E934', 'E935', 'E936', 'E937', 'E938', 'E939', 'E940', 'E941', 'E942', 'E943', 'E944', 'E945', 'E946', 'E947', 'E950', 'E953', 'E955', 'E956', 'E957', 'E958', 'E960', 'E965', 'E966', 'E967', 'E968', 'E969', 'E980', 'E988', 'E989', 'V01', 'V02', 'V03', 'V04', 'V05', 'V06', 'V07', 'V08', 'V09', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V23', 'V26', 'V27', 'V29', 'V30', 'V42', 'V43', 'V44', 'V45', 'V46', 'V49', 'V50', 'V53', 'V54', 'V55', 'V56', 'V58', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V69', 'V70', 'V72', 'V74', 'V76', 'DEAD', 'ASIAN', 'WHITE', 'UNKNOWN/NOT SPECIFIED', 'BLACK/AFRICAN AMERICAN', 'PATIENT DECLINED TO ANSWER', 'OTHER', 'HISPANIC OR LATINO', 'HISPANIC/LATINO - GUATEMALAN', 'ASIAN - CHINESE', 'HISPANIC/LATINO - PUERTO RICAN', 'ASIAN - ASIAN INDIAN', 'ASIAN - VIETNAMESE', 'MULTI RACE ETHNICITY', 'HISPANIC/LATINO - DOMINICAN', 'AMERICAN INDIAN/ALASKA NATIVE', 'WHITE - RUSSIAN', 'BLACK/AFRICAN', 'HISPANIC/LATINO - SALVADORAN', 'UNABLE TO OBTAIN', 'BLACK/CAPE VERDEAN', 'BLACK/HAITIAN', 'WHITE - OTHER EUROPEAN', 'PORTUGUESE', 'ASIAN - CAMBODIAN', 'SOUTH AMERICAN', 'WHITE - EASTERN EUROPEAN', 'ASIAN - FILIPINO', 'CARIBBEAN ISLAND', 'ASIAN - KOREAN', 'HISPANIC/LATINO - COLOMBIAN', 'WHITE - BRAZILIAN', 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER', 'HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)', 'ASIAN - JAPANESE', 'ASIAN - THAI', 'HISPANIC/LATINO - HONDURAN', 'HISPANIC/LATINO - CUBAN', 'MIDDLE EASTERN', 'ASIAN - OTHER', 'HISPANIC/LATINO - MEXICAN', 'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE']\n"
     ]
    }
   ],
   "source": [
    "df.columns.tolist()\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>LOS</th>\n",
       "      <th>HOSPITALIZATION</th>\n",
       "      <th>ORDINAL_AGE</th>\n",
       "      <th>ELECTIVE</th>\n",
       "      <th>EMERGENCY</th>\n",
       "      <th>NEWBORN</th>\n",
       "      <th>URGENT</th>\n",
       "      <th>Government</th>\n",
       "      <th>Medicaid</th>\n",
       "      <th>...</th>\n",
       "      <th>NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER</th>\n",
       "      <th>HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)</th>\n",
       "      <th>ASIAN - JAPANESE</th>\n",
       "      <th>ASIAN - THAI</th>\n",
       "      <th>HISPANIC/LATINO - HONDURAN</th>\n",
       "      <th>HISPANIC/LATINO - CUBAN</th>\n",
       "      <th>MIDDLE EASTERN</th>\n",
       "      <th>ASIAN - OTHER</th>\n",
       "      <th>HISPANIC/LATINO - MEXICAN</th>\n",
       "      <th>AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3613</th>\n",
       "      <td>20152</td>\n",
       "      <td>2.2232</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8903</th>\n",
       "      <td>79578</td>\n",
       "      <td>9.9925</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10299</th>\n",
       "      <td>99899</td>\n",
       "      <td>9.1439</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>19075</td>\n",
       "      <td>4.1865</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>11466</td>\n",
       "      <td>0.9083</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 921 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID     LOS  HOSPITALIZATION  ORDINAL_AGE  ELECTIVE  EMERGENCY  \\\n",
       "3613        20152  2.2232                1            7         0          1   \n",
       "8903        79578  9.9925                1            4         0          1   \n",
       "10299       99899  9.1439                1            9         0          1   \n",
       "3428        19075  4.1865                2            8         0          1   \n",
       "2025        11466  0.9083                1            7         0          1   \n",
       "\n",
       "       NEWBORN  URGENT  Government  Medicaid  ...  \\\n",
       "3613         0       0           0         0  ...   \n",
       "8903         0       0           0         0  ...   \n",
       "10299        0       0           0         0  ...   \n",
       "3428         0       0           0         0  ...   \n",
       "2025         0       0           0         0  ...   \n",
       "\n",
       "       NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER  \\\n",
       "3613                                           0   \n",
       "8903                                           0   \n",
       "10299                                          0   \n",
       "3428                                           0   \n",
       "2025                                           0   \n",
       "\n",
       "       HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)  ASIAN - JAPANESE  \\\n",
       "3613                                            0                 0   \n",
       "8903                                            0                 0   \n",
       "10299                                           0                 0   \n",
       "3428                                            0                 0   \n",
       "2025                                            0                 0   \n",
       "\n",
       "       ASIAN - THAI  HISPANIC/LATINO - HONDURAN  HISPANIC/LATINO - CUBAN  \\\n",
       "3613              0                           0                        0   \n",
       "8903              0                           0                        0   \n",
       "10299             0                           0                        0   \n",
       "3428              0                           0                        0   \n",
       "2025              0                           0                        0   \n",
       "\n",
       "       MIDDLE EASTERN  ASIAN - OTHER  HISPANIC/LATINO - MEXICAN  \\\n",
       "3613                0              0                          0   \n",
       "8903                0              0                          0   \n",
       "10299               0              0                          0   \n",
       "3428                0              0                          0   \n",
       "2025                0              0                          0   \n",
       "\n",
       "       AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE  \n",
       "3613                                                   0         \n",
       "8903                                                   0         \n",
       "10299                                                  0         \n",
       "3428                                                   0         \n",
       "2025                                                   0         \n",
       "\n",
       "[5 rows x 921 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample100= df.sample(n=100)\n",
    "sample100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 921)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEM = BatchExpectationMaximization( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-ddcd0cec2ca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBEM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ord_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Health-Care-Research/code/batch_expectation_maximization.py\u001b[0m in \u001b[0;36mimpute_missing\u001b[0;34m(self, X, cont_indices, ord_indices, threshold, max_iter, max_workers, max_ord, batch_size, num_ord_updates)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcont_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mord_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# guess the indices from the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mcont_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cont_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_ord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mord_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mcont_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Health-Care-Research/code/batch_expectation_maximization.py\u001b[0m in \u001b[0;36mget_cont_indices\u001b[0;34m(self, X, max_ord)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mcol_nonan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0mcol_unique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_nonan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_unique\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_ord\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "im = BEM.impute_missing(X, cont_indices=None, ord_indices=None, threshold=0.01, max_iter=100, max_workers=None, max_ord=100, batch_size=64, num_ord_updates=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9e17a89643fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#class BatchExpectationMaximization():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimputem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpute_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ord_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#class BatchExpectationMaximization():\n",
    "imputem = impute_missing(self, X, cont_indices=None, ord_indices=None, threshold=0.01, max_iter=100, max_workers=None, max_ord=100, batch_size=64, num_ord_updates=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _em_step_body_(args):\n",
    "    \"\"\"\n",
    "    Does a step of the EM algorithm, needed to dereference args to support parallelism\n",
    "    \"\"\"\n",
    "    return _em_step_body(*args)\n",
    "\n",
    "def _em_step_body(Z_row, r_lower_row, r_upper_row, sigma, num_ord, num_ord_updates):\n",
    "    \"\"\"\n",
    "    The body of the em algorithm for each row\n",
    "    Returns a new latent row, latent imputed row and C matrix, which, when added\n",
    "    to the empirical covariance gives the expected covariance\n",
    "    Args:\n",
    "        Z_row (array): (potentially missing) latent entries for one data point\n",
    "        r_lower_row (array): (potentially missing) lower range of ordinal entries for one data point\n",
    "        r_upper_row (array): (potentially missing) upper range of ordinal entries for one data point\n",
    "        sigma (matrix): estimate of covariance\n",
    "        num_ord (int): the number of ordinal columns\n",
    "        num_ord_updates (int): number of times to estimate ordinal mean\n",
    "    Returns:\n",
    "        C (matrix): results in the updated covariance when added to the empircal covariance\n",
    "        Z_imp_row (array): Z_row with latent ordinals updated and missing entries imputed \n",
    "        Z_row (array): inpute Z_row with latent ordinals updated\n",
    "    \"\"\"\n",
    "    p = Z_row.shape[0]\n",
    "    Z_imp_row = np.copy(Z_row)\n",
    "    C = np.zeros((p,p))\n",
    "    obs_indices = np.where(~np.isnan(Z_row))[0]\n",
    "    missing_indices = np.where(np.isnan(Z_row))[0]\n",
    "    ord_in_obs = np.where(obs_indices < num_ord)[0]\n",
    "    ord_obs_indices = obs_indices[ord_in_obs]\n",
    "    # obtain correlation sub-matrices\n",
    "    # obtain submatrices by indexing a \"cartesian-product\" of index arrays\n",
    "    sigma_obs_obs = sigma[np.ix_(obs_indices,obs_indices)]\n",
    "    sigma_obs_missing = sigma[np.ix_(obs_indices, missing_indices)]\n",
    "    sigma_missing_missing = sigma[np.ix_(missing_indices, missing_indices)]\n",
    "    # precompute psuedo-inverse \n",
    "    sigma_obs_obs_inv = np.linalg.pinv(sigma_obs_obs)\n",
    "    # precompute sigma_obs_obs_inv * simga_obs_missing\n",
    "    if len(missing_indices) > 0:\n",
    "        J_obs_missing = np.matmul(sigma_obs_obs_inv, sigma_obs_missing)\n",
    "    # initialize vector of variances for observed ordinal dimensions\n",
    "    var_ordinal = np.zeros(p)\n",
    "\n",
    "    # OBSERVED ORDINAL ELEMENTS\n",
    "    # when there is an observed ordinal to be imputed and another observed dimension, impute this ordinal\n",
    "    if len(obs_indices) >= 2 and len(ord_obs_indices) >= 1:\n",
    "        for update_iter in range(num_ord_updates):\n",
    "            # used to efficiently compute conditional mean\n",
    "            sigma_obs_obs_inv_Z_row = np.matmul(sigma_obs_obs_inv, Z_row[obs_indices])\n",
    "            for j in ord_obs_indices:\n",
    "                j_in_obs = np.where(obs_indices == j)[0]\n",
    "                not_j_in_obs = np.where(obs_indices != j)[0]\n",
    "                v = sigma_obs_obs_inv[:,j_in_obs]\n",
    "                new_var_ij = np.asscalar(1.0/v[j_in_obs])\n",
    "                new_mean_ij = Z_row[j] - new_var_ij*sigma_obs_obs_inv_Z_row[j_in_obs]\n",
    "                # the boundaries must be de-meaned and normalized\n",
    "                mean, var = truncnorm.stats(\n",
    "                    a=(r_lower_row[j] - new_mean_ij) / np.sqrt(new_var_ij),\n",
    "                    b=(r_upper_row[j] - new_mean_ij) / np.sqrt(new_var_ij),\n",
    "                    loc=new_mean_ij,\n",
    "                    scale=np.sqrt(new_var_ij),\n",
    "                    moments='mv'\n",
    "                )\n",
    "                if np.isfinite(var):\n",
    "                    var_ordinal[j] = var\n",
    "                    if update_iter == num_ord_updates - 1:\n",
    "                        # update the variance estimate\n",
    "                        C[j,j] = C[j,j] + var\n",
    "                if np.isfinite(mean):\n",
    "                    Z_row[j] = mean\n",
    "    Z_obs = Z_row[obs_indices]\n",
    "    # mean expection and imputation\n",
    "    Z_imp_row[obs_indices] = Z_obs\n",
    "    # MISSING ELEMENTS\n",
    "    if len(missing_indices) > 0:\n",
    "        Z_imp_row[missing_indices] = np.matmul(J_obs_missing.T,Z_obs)\n",
    "        # variance expectation and imputation\n",
    "        if len(ord_obs_indices) >= 1 and len(obs_indices) >= 2 and np.sum(var_ordinal) > 0:\n",
    "            diag_var_ord = np.diag(var_ordinal[ord_obs_indices])\n",
    "            cov_missing_obs_ord = np.matmul(J_obs_missing[ord_in_obs].T, diag_var_ord)\n",
    "            C[np.ix_(missing_indices, ord_obs_indices)] += cov_missing_obs_ord\n",
    "            C[np.ix_(ord_obs_indices, missing_indices)] += cov_missing_obs_ord.T\n",
    "            C[np.ix_(missing_indices, missing_indices)] += sigma_missing_missing - np.matmul(J_obs_missing.T, sigma_obs_missing) + np.matmul(cov_missing_obs_ord, J_obs_missing[ord_in_obs])\n",
    "        else:\n",
    "            C[np.ix_(missing_indices, missing_indices)] += sigma_missing_missing - np.matmul(J_obs_missing.T, sigma_obs_missing)\n",
    "    return C, Z_imp_row, Z_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-19-99e9375dd1ff>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-99e9375dd1ff>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def impute_missing(self, X, cont_indices=None, ord_indices=None, threshold=0.01, max_iter=100, max_workers=None, max_ord=100, batch_size=64, num_ord_updates=2):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class BatchExpectationMaximization():\n",
    "    def impute_missing(self, X, cont_indices=None, ord_indices=None, threshold=0.01, max_iter=100, max_workers=None, max_ord=100, batch_size=64, num_ord_updates=2):\n",
    "        \"\"\"\n",
    "        Fits a Gaussian Copula and imputes missing values in X.\n",
    "        Args:\n",
    "            X (matrix): data matrix with entries to be imputed\n",
    "            cont_indices (array): indices of the continuous entries\n",
    "            ord_indices (array): indices of the ordinal entries\n",
    "            threshold (float): the threshold for scaled difference between covariance estimates at which to stop early\n",
    "            max_iter (int): the maximum number of iterations for copula estimation\n",
    "            max_workers: the maximum number of workers for parallelism \n",
    "            max_ord: maximum number of levels in any ordinal for detection of ordinal indices\n",
    "            batch_size: the number of elements to process in each iteration for copula update\n",
    "            num_ord_updates: the number of times to re-estimate the latent ordinals per batch\n",
    "        Returns:\n",
    "            X_imp (matrix): X with missing values imputed\n",
    "            sigma_rearragned (matrix): an estimate of the covariance of the copula\n",
    "        \"\"\"\n",
    "        if cont_indices is None and ord_indices is None:\n",
    "            # guess the indices from the data\n",
    "            cont_indices = self.get_cont_indices(X, max_ord=max_ord)\n",
    "            ord_indices = ~cont_indices\n",
    "        self.transform_function = TransformFunction(X, cont_indices, ord_indices)\n",
    "        sigma, Z_imp = self._fit_covariance(X, cont_indices, ord_indices, threshold, max_iter, max_workers, batch_size, num_ord_updates)\n",
    "        # rearrange sigma so it corresponds to the column ordering of X\n",
    "        sigma_rearranged = np.empty(sigma.shape)\n",
    "        sigma_rearranged[np.ix_(ord_indices,ord_indices)] = sigma[:np.sum(ord_indices),:np.sum(ord_indices)]\n",
    "        sigma_rearranged[np.ix_(cont_indices,cont_indices)] = sigma[np.sum(ord_indices):,np.sum(ord_indices):]\n",
    "        sigma_rearranged[np.ix_(cont_indices,ord_indices)] = sigma[np.sum(ord_indices):,:np.sum(ord_indices)]\n",
    "        sigma_rearranged[np.ix_(ord_indices,cont_indices)] =  sigma_rearranged[np.ix_(cont_indices,ord_indices)].T\n",
    "        # Rearrange Z_imp so that it's columns correspond to the columns of X\n",
    "        Z_imp_rearranged = np.empty(X.shape)\n",
    "        Z_imp_rearranged[:,ord_indices] = Z_imp[:,:np.sum(ord_indices)]\n",
    "        Z_imp_rearranged[:,cont_indices] = Z_imp[:,np.sum(ord_indices):]\n",
    "        X_imp_cont = np.copy(X[:,cont_indices])\n",
    "        X_imp_ord = np.copy(X[:,ord_indices])\n",
    "        # Impute continuous\n",
    "        X_imp_cont[np.isnan(X_imp_cont)] = self.transform_function.impute_cont_observed(Z_imp_rearranged)[np.isnan(X_imp_cont)]\n",
    "        # Impute ordinal\n",
    "        X_imp_ord[np.isnan(X_imp_ord)] = self.transform_function.impute_ord_observed(Z_imp_rearranged)[np.isnan(X_imp_ord)]\n",
    "        X_imp = np.empty(X.shape)\n",
    "        X_imp[:,cont_indices] = X_imp_cont\n",
    "        X_imp[:,ord_indices] = X_imp_ord\n",
    "       # return X_imp, sigma_rearranged\n",
    "        print(X_imp, sigma_rearranged)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    print(X_imp, sigma_rearranged)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def impute_missing(self, X, cont_indices=None, ord_indices=None, threshold=0.01, max_iter=100, max_workers=None, max_ord=100, batch_size=64, num_ord_updates=2):\n",
    " \"\"\"\n",
    " Fits a Gaussian Copula and imputes missing values in X.\n",
    " Args:\n",
    "            X (matrix): data matrix with entries to be imputed\n",
    "            cont_indices (array): indices of the continuous entries\n",
    "            ord_indices (array): indices of the ordinal entries\n",
    "            threshold (float): the threshold for scaled difference between covariance estimates at which to stop early\n",
    "            max_iter (int): the maximum number of iterations for copula estimation\n",
    "            max_workers: the maximum number of workers for parallelism \n",
    "            max_ord: maximum number of levels in any ordinal for detection of ordinal indices\n",
    "            batch_size: the number of elements to process in each iteration for copula update\n",
    "            num_ord_updates: the number of times to re-estimate the latent ordinals per batch\n",
    "        Returns:\n",
    "            X_imp (matrix): X with missing values imputed\n",
    "            sigma_rearragned (matrix): an estimate of the covariance of the copula\n",
    "        \"\"\"\n",
    "    if cont_indices is None and ord_indices is None:\n",
    "        # guess the indices from the data\n",
    "        cont_indices = self.get_cont_indices(X, max_ord=max_ord)\n",
    "        ord_indices = ~cont_indices\n",
    "    self.transform_function = TransformFunction(X, cont_indices, ord_indices)\n",
    "    sigma, Z_imp = self._fit_covariance(X, cont_indices, ord_indices, threshold, max_iter, max_workers, batch_size, num_ord_updates)\n",
    "    # rearrange sigma so it corresponds to the column ordering of X\n",
    "    sigma_rearranged = np.empty(sigma.shape)\n",
    "    sigma_rearranged[np.ix_(ord_indices,ord_indices)] = sigma[:np.sum(ord_indices),:np.sum(ord_indices)]\n",
    "    sigma_rearranged[np.ix_(cont_indices,cont_indices)] = sigma[np.sum(ord_indices):,np.sum(ord_indices):]\n",
    "    sigma_rearranged[np.ix_(cont_indices,ord_indices)] = sigma[np.sum(ord_indices):,:np.sum(ord_indices)]\n",
    "    sigma_rearranged[np.ix_(ord_indices,cont_indices)] =  sigma_rearranged[np.ix_(cont_indices,ord_indices)].T\n",
    "    # Rearrange Z_imp so that it's columns correspond to the columns of X\n",
    "    Z_imp_rearranged = np.empty(X.shape)\n",
    "    Z_imp_rearranged[:,ord_indices] = Z_imp[:,:np.sum(ord_indices)]\n",
    "    Z_imp_rearranged[:,cont_indices] = Z_imp[:,np.sum(ord_indices):]\n",
    "    X_imp_cont = np.copy(X[:,cont_indices])\n",
    "    X_imp_ord = np.copy(X[:,ord_indices])\n",
    "    # Impute continuous\n",
    "    X_imp_cont[np.isnan(X_imp_cont)] = self.transform_function.impute_cont_observed(Z_imp_rearranged)[np.isnan(X_imp_cont)]\n",
    "    # Impute ordinal\n",
    "    X_imp_ord[np.isnan(X_imp_ord)] = self.transform_function.impute_ord_observed(Z_imp_rearranged)[np.isnan(X_imp_ord)]\n",
    "    X_imp = np.empty(X.shape)\n",
    "    X_imp[:,cont_indices] = X_imp_cont\n",
    "    X_imp[:,ord_indices] = X_imp_ord\n",
    "   # return X_imp, sigma_rearranged\n",
    "    print(X_imp, sigma_rearranged)\n",
    " print(X_imp, sigma_rearranged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _fit_covariance(self, X, cont_indices, ord_indices, threshold, max_iter, max_workers, batch_size, num_ord_updates):\n",
    "        \"\"\"\n",
    "        Fits the covariance matrix of the gaussian copula using the data \n",
    "        in X and returns the imputed latent values corresponding to \n",
    "        entries of X and the covariance of the copula\n",
    "        Args:\n",
    "            X (matrix): data matrix with entries to be imputed\n",
    "            cont_indices (array): indices of the continuous entries\n",
    "            ord_indices (array): indices of the ordinal entries\n",
    "            threshold (float): the threshold for scaled difference between covariance estimates at which to stop early\n",
    "            max_iter (int): the maximum number of iterations for copula estimation\n",
    "            max_workers: the maximum number of workers for parallelism \n",
    "            batch_size: the number of elements to process in each iteration for copula update\n",
    "            num_ord_updates: the number of times to restimate the latent ordinals per batch\n",
    "        Returns:\n",
    "            sigma (matrix): an estimate of the covariance of the copula\n",
    "            Z_imp (matrix): estimates of latent values\n",
    "        \"\"\"\n",
    "        assert cont_indices is not None or ord_indices is not None\n",
    "        assert cont_indices is not None or ord_indices is not None\n",
    "        Z_ord = None\n",
    "        if ord_indices is not None:\n",
    "           Z_ord_lower, Z_ord_upper = self.transform_function.get_ord_latent()\n",
    "           Z_ord = self._init_Z_ord(Z_ord_lower, Z_ord_upper)\n",
    "        Z_cont = None\n",
    "        if cont_indices is not None:\n",
    "            Z_cont = self.transform_function.get_cont_latent()\n",
    "        Z_imp = np.concatenate((Z_ord,Z_cont), axis=1)\n",
    "        # mean impute the missing continuous values for the sake of covariance estimation\n",
    "        Z_imp[np.isnan(Z_imp)] = 0.0\n",
    "        # initialize the correlation matrix\n",
    "        sigma = np.corrcoef(Z_imp, rowvar=False)\n",
    "        # Latent variable matrix with columns sorted as ordinal, continuous\n",
    "        Z = np.concatenate((Z_ord, Z_cont), axis=1)\n",
    "        n = Z.shape[0]\n",
    "        p = Z.shape[1]\n",
    "        if np.all(np.isnan(Z_ord_lower)):\n",
    "            num_ord = 0\n",
    "        else:\n",
    "            num_ord = Z_ord_lower.shape[1]\n",
    "        # track previous sigma for the purpose of early stopping\n",
    "        prev_sigma = self._project_to_correlation(sigma)\n",
    "        # permutation of indices of data for stochastic fitting\n",
    "        training_permutation = np.random.permutation(n)\n",
    "        Z_imp = np.zeros((n, p))\n",
    "        for batch_iter in range(max_iter):\n",
    "            batch_lower = (batch_iter * batch_size) % n\n",
    "            batch_upper = ((batch_iter+1) * batch_size) % n\n",
    "            if batch_upper < batch_lower:\n",
    "                # we have wrapped around the dataset\n",
    "                indices = np.concatenate((training_permutation[batch_lower:], training_permutation[:batch_upper]))\n",
    "            else:\n",
    "                indices = training_permutation[batch_lower:batch_upper]\n",
    "            C_batch = np.zeros((p, p))\n",
    "            args = [(np.copy(Z[i,:]), np.copy(Z_ord_lower[i,:]), np.copy(Z_ord_upper[i,:]), sigma, num_ord, num_ord_updates) for i in indices]\n",
    "            with ProcessPoolExecutor(max_workers=max_workers) as pool:\n",
    "                res = pool.map(_em_step_body_, args)\n",
    "                for i,(C_row, Z_imp_row, Z_row) in enumerate(res):\n",
    "                    Z_imp[indices[i],:] = Z_imp_row\n",
    "                    Z[indices[i],:] = Z_row\n",
    "                    C_batch += C_row/batch_size\n",
    "            sigma_batch = np.cov(Z_imp[indices,:], rowvar=False) + C_batch\n",
    "            sigma_batch = self._project_to_correlation(sigma_batch)\n",
    "            decay_coef = 1/(np.sqrt(batch_iter + 1))\n",
    "            sigma = sigma_batch*decay_coef + (1 - decay_coef)*prev_sigma\n",
    "            if self._get_scaled_diff(prev_sigma, sigma) < threshold:\n",
    "                break\n",
    "            prev_sigma = sigma\n",
    "        return sigma, Z_imp\n",
    "\n",
    "    def _project_to_correlation(self, covariance):\n",
    "        \"\"\"\n",
    "        Projects a covariance to a correlation matrix, normalizing it's diagonal entries\n",
    "        Args:\n",
    "            covariance (matrix): a covariance matrix\n",
    "        Returns:\n",
    "            correlation (matrix): the covariance matrix projected to a correlation matrix\n",
    "        \"\"\"\n",
    "        D = np.diagonal(covariance)\n",
    "        D_neg_half = np.diag(1.0/np.sqrt(D))\n",
    "        return np.matmul(np.matmul(D_neg_half, covariance), D_neg_half)\n",
    "\n",
    "    def _init_Z_ord(self, Z_ord_lower, Z_ord_upper):\n",
    "        \"\"\"\n",
    "        Initializes the observed latent ordinal values by sampling from a standard\n",
    "        Gaussian trucated to the inveral of Z_ord_lower, Z_ord_upper\n",
    "        Args:\n",
    "            Z_ord_lower (matrix): lower range for ordinals\n",
    "            Z_ord_upper (matrix): upper range for ordinals\n",
    "        Returns:\n",
    "            Z_ord (range): Samples drawn from gaussian truncated between Z_ord_lower and Z_ord_upper\n",
    "        \"\"\"\n",
    "        Z_ord = np.empty(Z_ord_lower.shape)\n",
    "        Z_ord[:] = np.nan\n",
    "        u_lower = np.copy(Z_ord_lower)\n",
    "        u_lower[~np.isnan(Z_ord_lower)] = norm.cdf(Z_ord_lower[~np.isnan(Z_ord_lower)])\n",
    "        u_upper = np.copy(Z_ord_upper)\n",
    "        u_upper[~np.isnan(Z_ord_upper)] = norm.cdf(Z_ord_upper[~np.isnan(Z_ord_upper)])\n",
    "        u_samples = np.random.uniform(u_lower[~np.isnan(u_lower)],u_upper[~np.isnan(u_lower)])\n",
    "        # convert back from the uniform sample to the guassian sample in that interval\n",
    "        Z_ord[~np.isnan(u_lower)] = norm.ppf(u_samples)\n",
    "        return Z_ord\n",
    "\n",
    "    def _get_scaled_diff(self, prev_sigma, sigma):\n",
    "        \"\"\"\n",
    "        Get's the scaled difference between two correlation matrices\n",
    "        Args:\n",
    "            prev_sigma (matrix): previous estimate of a matrix\n",
    "            sigma (matrix): current estimate of a matrix\n",
    "        Returns: \n",
    "            diff (float): scaled distance between the inputs\n",
    "        \"\"\"\n",
    "        return np.linalg.norm(sigma - prev_sigma) / np.linalg.norm(sigma)\n",
    "\n",
    "    def get_cont_indices(self, X, max_ord):\n",
    "        \"\"\"\n",
    "        get's the indices of continuos columns by returning\n",
    "        those indicies which have at least max_ord distinct values\n",
    "        Args:\n",
    "            X (matrix): input matrix\n",
    "            max_ord (int): maximum number of distinct values an ordinal can take on in a column\n",
    "        Returns:\n",
    "            indices (array): indices of the columns which have at most max_ord distinct entries\n",
    "        \"\"\"\n",
    "        indices = np.zeros(X.shape[1]).astype(bool)\n",
    "        for i, col in enumerate(X.T):\n",
    "            col_nonan = col[~np.isnan(col)]\n",
    "            col_unique = np.unique(col_nonan)\n",
    "            if len(col_unique) > max_ord:\n",
    "                indices[i] = True\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'em.expectation_maximization'; 'em' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2e8d6b537712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpectation_maximization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExpectationMaximization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_correlation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'em.expectation_maximization'; 'em' is not a package"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from em.expectation_maximization import ExpectationMaximization\n",
    "from scipy.stats import random_correlation, norm, expon\n",
    "from evaluation.helpers import *\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'expon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ba6ced9a3a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcont_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcont_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expon' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_sigma():\n",
    "    W = np.random.normal(size=(15,15))\n",
    "    covariance = np.matmul(W,W.T)\n",
    "    D = np.diagonal(covariance)\n",
    "    D_neg_half = np.diag(1.0/np.sqrt(D))\n",
    "    return np.matmul(np.matmul(D_neg_half, covariance), D_neg_half)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Note: the results of this experiement vary slightly from the analagous experiment presented in Landgrebe, E., Zhao, Y., and Udell, M. Online Mixed Missing Value Imputation Using Gaussian Copula, 2020.\n",
    "    scaled_errors = []\n",
    "    smaes = []\n",
    "    rmses = []\n",
    "    NUM_STEPS = 10\n",
    "    BATCH_SIZE = 40\n",
    "    MAX_ITER = 100\n",
    "    runtimes = []\n",
    "    for i in range(1,NUM_STEPS+1):\n",
    "        np.random.seed(i)\n",
    "        print(\"starting epoch: \" + str(i))\n",
    "        print(\"\\n\")\n",
    "        sigma = generate_sigma()\n",
    "        mean = np.zeros(sigma.shape[0])\n",
    "        X = np.random.multivariate_normal(mean, sigma, size=2000)\n",
    "        X[:,:5] = expon.ppf(norm.cdf(X[:,:5]), scale = 3)\n",
    "        X[:,5] = cont_to_binary(X[:,5])\n",
    "        X[:,6] = cont_to_binary(X[:,6])\n",
    "        X[:,7] = cont_to_binary(X[:,7])\n",
    "        X[:,8] = cont_to_binary(X[:,8])\n",
    "        X[:,9] = cont_to_binary(X[:,9])\n",
    "        X[:,10] = cont_to_ord(X[:,10], k=5)\n",
    "        X[:,11] = cont_to_ord(X[:,11], k=5)\n",
    "        X[:,12] = cont_to_ord(X[:,12], k=5)\n",
    "        X[:,13] = cont_to_ord(X[:,13], k=5)\n",
    "        X[:,14] = cont_to_ord(X[:,14], k=5)\n",
    "        # mask a given % of entries\n",
    "        MASK_FRACTION = 0.3\n",
    "        X_masked, mask_indices = mask(X, MASK_FRACTION)\n",
    "        bem = BatchExpectationMaximization()\n",
    "        start_time = time.time()\n",
    "        X_imp, sigma_imp = bem.impute_missing(X_masked, max_iter=MAX_ITER, batch_size=BATCH_SIZE, max_workers=None)\n",
    "        end_time = time.time()\n",
    "        runtimes.append(end_time - start_time)\n",
    "        scaled_error = get_scaled_error(sigma_imp, sigma)\n",
    "        smae = get_smae(X_imp, X, X_masked)\n",
    "        # update error to be normalized\n",
    "        rmse = get_scaled_error(X_imp[:,:5], X[:,:5])\n",
    "        scaled_errors.append(scaled_error)\n",
    "        smaes.append(smae)\n",
    "        rmses.append(rmse)\n",
    "    print(\"mean of scaled errors is: \")\n",
    "    print(np.mean(np.array(scaled_errors)))\n",
    "    print(\"std deviation of scaled errors is: \")\n",
    "    print(np.std(np.array(scaled_errors)))\n",
    "    print(\"\\n\")\n",
    "    mean_smaes = np.mean(np.array(smaes),axis=0)\n",
    "    print(\"mean cont smaes are: \")\n",
    "    print(np.mean(mean_smaes[:5]))\n",
    "    print(\"mean bin smaes are: \")\n",
    "    print(np.mean(mean_smaes[5:10]))\n",
    "    print(\"mean ord smaes are: \")\n",
    "    print(np.mean(mean_smaes[10:]))\n",
    "    print(\"\\n\")\n",
    "    std_dev_smaes = np.std(np.array(smaes),axis=0)\n",
    "    print(\"std dev cont smaes are: \")\n",
    "    print(np.mean(std_dev_smaes[:5]))\n",
    "    print(\"std dev bin smaes are: \")\n",
    "    print(np.mean(std_dev_smaes[5:10]))\n",
    "    print(\"std dev ord smaes are: \")\n",
    "    print(np.mean(std_dev_smaes[10:]))\n",
    "    print(\"\\n\")\n",
    "    print(\"mean of rmses is: \")\n",
    "    print(np.mean(np.array(rmses),axis=0))\n",
    "    print(\"std deviation of rmses is: \")\n",
    "    print(np.std(np.array(rmses),axis=0))\n",
    "    print(\"\\n\")\n",
    "    print(\"mean time for run is: \")\n",
    "    print(np.mean(np.array(runtimes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
